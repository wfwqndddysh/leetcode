关于安全的elk改造，分为三个大的步骤：

一：梳理现有的elk：

    1. elk管理的log种类: 现有系统收集、存储、展示、上报了哪些类型的log:
        a. ids
        b. ddos
        c. waf
        ...
        针对每种log，需要整理出全数据流程及每一环的责任人，如:

        ddos： 设备(syslog)[鲍昀]---->logstash[张建军，李研]---->kafka[张, 李]---->logstash[张，李]---->es[张，李]，集团[张，李]

    2. 处理log的elk系统, 1中的每一环都要梳理出详情出来

        每一环的机器地址，程序版本，进程管理方式(work dir， start/restart method), 常见问题排除思路及过程，及主要配置参数和参数的目的都要明确下来

        这一部分的工作，在去年已经做了一大部分了（见我画的大图），把剩下的再加上


        目前需要整理的内容大致如下，过程中如发现新的，随时加入


        机房  集群地址  虚拟机/物理  登录方式/权限  负责人  主要作用  程序目录  版本(包括主要插件版本)  启停方式  主配置参数  日志目录  常见问题及处理方法  前一环节  后一环节


        主配置参数包括但不限于：
        input source， thread num， kafka group， 处理的log的appname,  output address


二：加固现有架构；

    目前这些机器只是系统运维层面加了最基本的监控，比如空间不足等, 有几次数据断了后，我们并不知道，针对这种情况，要把足够的监控加上去。

    年前我应急给常出问题的两台logstash加了bash脚步，在crontab里，同时李研也用python写了部分脚步

    我们要梳理出来，那些指标需要加上监控，并及时加上, 具体做法：

    针对第一步的表格，每个集群都要加上需要的监控，保证数据中断能及时发现


三：将需要的地方改造为更合理的架构：

    如刘俊说，目前整套系统还是最原始的架构及管理方式, 存在某些不合理或者不方便管理的地方, 针对性的做一些调整，最主要时logstash部分

    这一部分还在调研

